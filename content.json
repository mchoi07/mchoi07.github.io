{"pages":[{"title":"","text":"","link":"/404.html"},{"title":"About Minkyu Choi","text":"IntroMinkyu Choi is a Artificial Intelligence &amp; Machine Learning Engineer working in the various industries around 3 years as a consultant. He had worked in a commerical sectors for a couple of years and moved to government sectors. He has been exposed to diverse machine learning and deep learning projects, experienced in various big data engineering projects including Hadoop, Spark, Kafka, etc. Minkyu’s Expertises ML/AI Infrastructure Cloud Computing &amp; Architect (Amazon Web Service) Data Pipelining — Batch &amp; Streaming Machine Learning &amp; Deep Learning Github LinkedIn Email #contact-buttons { width: 100%; display: flex; } #contact-butons a.button { flex-grow: 1; } @media screen and (max-width: 720px) { #contact-buttons a.button { width: 100%; margin-right: 0; } } EducactionGeorgia Institute of TechnologyMS in Data Science Knowledge-Based Artificial Intelligence: Cognitive Systems Big Data for Healthcare Computational Data Analytics (Machine Learning) Machine Learning For Trading High-Dimensional Data Analysis Baruch CollegeBBA in Computer Information System Data Warehousing Database Management System Quantiative Decision Making Regression and Forecasting Modeling ProfessionalUnited States Department of Defense (The Joint Artifical Intelligence Center)Artificial Intelligence Engineer Project Overview: The Joint Artificial Intelligence Center (JAIC) is the Department of Defense’s (DoD) Artificial Intelligence (AI) Center of Excellence that provides a critical mass of expertise to help the Department harness the game-changing power of AI. Architecting an infrastructure of DoD AI/ML platform Developing a data strategy and capability of the JAIC Common Foundation (JCF) Participating a ML/DL model development within CI/CD ML DevOpsSec life cycle Techfield LLCSubject Matter Expert in Big Data and Data Science Managed +10 consultants in the big data and data science team, supporting the projects such as a cloud data pipeline solution and an automated application platform with a machine learning system Worked closely with one of the fortune 500 client in order to accomplish a goal of the datapipeline project for the entire batch and streaming processing and achieved a cost reductionand efficient processing time Endpoint ClinicalData Engineer Worked as a back-end database developer of IRT system – providing integrated solution of clinical trials (e.g., patient record, drug supply management and site management) in order to provide technical solution for large size of pharmaceutical clients Argus Information and Advisory ServicesData Analyst Developed strategies, best practices, and technical requirements to improve data manipulation and analysis by querying millions of rows of data across multiple databases, using MS SQL Server to identify and resolve data issues, and leveraged large sets of data to define benchmark models to enable client’s objectives to better manage data and drive insights SkillPrograming &amp; Scripting Language: Scala | Java | Python | R |Bash |Big Data Application: Hadoop | Spark | Kafka | Flume | Nifi | Sqoop | ELK |Database: MySql | Cassandra | Hbase | Elasticsearch | DynamoDB |","link":"/about/index.html"}],"posts":[{"title":"Simulation 01 - Random Number","text":"A simulation is not real but it can represent the real. It’s because a simulation is an imitation of real situation - it can’t be exact but it can be approximate. Most of simulation models are strated from generating random number because randomness creates value on a simulation modeling. It is really important to give an algorithm that produces a sequence of pseudo-random number (PRNs) $R_1, R_2,…$ that “appear” to be iid Unif(0,1). There are many different Uniform(0,1) Generators. Output of random device Nice randomness properties. However, Unif(0,1) sequence storage difficult, sot it’s tough to repeat experiment Examples: flip a coin particle count by Geiger coutner least significant digits of atomic clock Table of random numbers List of digits supplied in tables - A Million random Digits with 100,00 Normal Deviates. Cumbersome, slow, table too small - not very useful Mid-Square Idea - Take the middle part of square of the previous random number. John von Neumann was a brilliant and fun-loving guy, but method is terrible Example: Take $R_i = X_i/10000$, ∀i, where the Xi’s are positiveintegers &lt; 10000. Set seed $X_0 = 6642$; then $6632^2$ = 43983424 so $X_1 = 9834$; then $9834^2$ - 96707556 so $X_2$ = 7075, etc,… Unfortunately, positive serial correlation in $R_i$’s. Also, occasionally degenerates; eg., consider $X_i$ = 0003 Fibonacci These methods are also no good!! Take $X_i = (X_{i-1} + X_{i-2})mod(m), i = 1,2,…,$ where $R_i = X_i/m$ ,$m$ is the modulus, $X_01,X_0$ are seeds, and $a = b mod m$ if $a$ is the remainer of $b/m$ Problem: small numbers follow small numbers Also, it’s not possible to get $X_{i-1} &lt; X_{i+1} &lt; X_i$ or $X_i &lt; X_{i+1} &lt; X_{i-1} $ (which should occur w.p 1/3) $X_{i+1}$ Linear congruential (most commonly used in practice LCGs are the most widely used generators. These are pretty good when implemented properly. $X_i = (aX_{i-1} + c) mod(m)$, where $X_0$ is the seed. $R_i = X_i/m, i = 1,2,…$ Choose a,c,m carefully to get good stastistical quality and long period or cycle length, i.e., time until LCG starts to repeat itself. If $c = 0$, LCG is called a multiplicative generator Tausworthe (linear recursion mod 2) Tausworthe Generator is a kind of multicative recursive generator. $X_{i+1} = (aX_{i-1} + c) mod(2)$, where $X_0$ is the seed. Reference Georgia Tech’s ISYE6644 class content","link":"/2019/07/18/random-number/"},{"title":"Simulation 02 - Random variable","text":"Random variable can be generated from a good random number generator. If real variables has moved the reality, we could design a future with a good random variables. Author: Minkyu ChoiLast updated: 07/19/2019 Inverse Transform MethodInverse transform sampling is a method for generating random numbers from any probability distribution by using its inverse cumulative distribution F−1(x)F−1(x). Recall that the cumulative distribution for a random variable XX is FX(x)=P(X≤x)FX(x)=P(X≤x). In what follows, we assume that our computer can, on demand, generate independent realizations of a random variable UU uniformly distributed on [0,1] Cutpoint MethodThis inverse-transform method has the advantage of having an optimal O(n) setup time. However, the average number of steps required to sample X is not optimal, and if several samples of X are needed, then the cutpoint method offers an average number of two comparison steps needed to sample an observation, yet still has an O(n) initial setup time Without loss of generality, we can assume that X = [1, n]. Also, let qi = P(X ≤ i). Then the idea behind the cutpoint method is to choose m ≥ n, and define sets Q1, . . . , Qm for which for all i = 1, . . . , m. In words, the unit interval [0, 1] is partitioned into m equal sub-intervals of the form $[\\frac{(i−1)} m, \\frac{i}m)$, i = 1, . . . , m. And when U falls into the i th sub-interval, then Qi contains all the possible qj values for which F −1 (U) = j. That way, instead of searching through all of the q values, we save time by only examining the qj values in Qi , since these are the only possible values for which $F^{-1} (U) = j$. Convolution Method Sum of n variables: $x = y_1 + y_2 + … y_n$ Generate n random variate yi’s and sum For sums of two variables, pdf of x = convolution of pdfs of y1 and y2. Hence the name Although no convolution in generation If pdf or CDF = Sum ⇒ Composition Variable x = Sum ⇒ Convolution Acceptance-Rejection MethodFinding an explicit formula for F −1 (y) for the cdf of a rv X we wish to generate, F(x) = P(X ≤ x), is not always possible. Moreover, even if it is, there may be alternative methods for generating a rv distributed as F that is more efficient than the inverse transform method or other methods we have come across. Here we present a very clever method known as the acceptance-rejection method. Composition MethodCan be used when m can be expressed as a convex combination of other distributions Fi , where we hope to be able to sample from $F_i$ more easily than from F directly. ReferencesLink-1Link-2Link-3Link-4Link-5","link":"/2019/07/19/random-variable/"},{"title":"Realtime Virus Scanning","text":"To protect our system and computer we should make sure that data which we download is clean. Everytime we bring data to our system or user upload data such as file attachments, we must make sure that data is free from viruses and trojans. If our system has sensitive data and critical for operation you have to be more cautious about bringing data to your system - cyber attack, nowadays, is being serious and cunning. In a normal usecase, we set up Anti Virus (AV) scanner on a file system. AV scanner monitor our file system and RAM in real-time or batch. However, it cannot make sure that each file doesn’t have any malicious content in real-time. In this project, we will use two open source products to detect virus/trojan in realtime. We are going to use Apache Nifi and ClamAV Apache Nifi is a very powerful, easy to use and stable system to process and distribute data between disparate system. Apache Nifi is a real time data ingestion platform, which can transfer and manage data transfer between different sources and destination systems. ClamAV is an open source antivirus engine for detecting trojans, viruses, malware &amp; other malicious threats. ReferenceThumnail Image","link":"/2019/07/19/nifi-virus-scanning/"}],"tags":[{"name":"simulation","slug":"simulation","link":"/tags/simulation/"},{"name":"Apache Nifi","slug":"apache-nifi","link":"/tags/apache-nifi/"}],"categories":[{"name":"ENG-Statistics","slug":"eng-statistics","link":"/categories/eng-statistics/"},{"name":"ENG-Data Engineering","slug":"eng-data-engineering","link":"/categories/eng-data-engineering/"}]}